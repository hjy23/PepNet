```
                        Installation and implementation of PepNet
                                (version 1.0 2024/05/27)

1 Description
    PepNet is an interpretable deep learning framework for predicting peptides with antimicrobial or anti-inflammatory activities by using a pretrained protein language model to fully extract function related diverse peptide features.
    For a given peptide, PepNet first extracts the original features, which are fed into the residual dilated convolution block to capture the spaced neighboring information, and the pre-trained features, which contain richer, more informative and more generalized sequence information. Furthermore, the sequence features encoded by the residual dilated convolution block, along with the pre-trained features, are fed into the residual Transformer block to capture the global information via considering all the positional information from the peptide sequence. Finally, an average pool operation is used to obtain the peptide representation, which is then inputted into the classification layer for binary prediction.
2 Installation

2.1 system requirements
    For prediction process, you can predict functional binding residues from a protein structure within a few minutes with CPUs only. However, for training a new deep model from scratch, we recommend using a GPU for significantly faster training.
    To use PepNet with GPUs, you will need: cuda >= 10.0, cuDNN.

2.2 Create an environment
    PepNet is built on Python3.
    We highly recommend to use a virtual environment for the installation of PepNet and its dependencies.

    A virtual environment can be created and (de)activated as follows by using conda(https://conda.io/docs/):
        # create
        $ conda create -n PepNet python=3.6
        # activate
        $ source activate PepNet
        # deactivate
        $ source deactivate
    OR the virtual environment can be created by using virtualenv(https://github.com/pypa/virtualenv/).
        # create
        $ virtualenv PepNet --python=python3.6
        # activate
        $ source PepNet/bin/activate
        # deactivate
        $ deactivate

2.3 Install PepNet dependencies
    Note: If you are using a Python virtual environment, make sure it is activated before running each command in this guide.

2.3.1 Install requirements
	
	Note: Typical install requirements time on a "normal" desktop computer is 10 minutes. This is an install example, you can also install the latest versions of pytorch and torch-geometric, but please pay attention to compatibility issues between versions when installing.
	
    (1) Install pytorch 1.2.0 (For more details, please refer to https://pytorch.org/)
        For linux:
        # CUDA 10.0
        $ pip install torch===1.2.0 torchvision===0.4.0 -f https://download.pytorch.org/whl/torch_stable.html
        # CPU only
        $ pip install torch==1.2.0+cpu torchvision==0.4.0+cpu -f https://download.pytorch.org/whl/torch_stable.html


2.3.2 Extraction the pretrained features generated by ProtT5-XL-U50
    (1) Download the source code of ProtTrans from https://github.com/agemagician/ProtTrans.
    (2) Download the ProtT5-XL-U50 model.
    (3) Generate the pretrained feature for a fasta file.
        $ cd {ProtTrans_path}/Embedding
        $ python prott5_embedder.py --input {the path of the fasta file} --output {the path of the output H5PY file, e.g, out.h5} --model {the path of the ProtT5-XL-U50 model you download}

    Note: Before runing ProtTrans, please install the required dependencies of ProtTrans.



3 Usage

3.1 Predict AMPs or AIPs based on trained deep models

3.1.1 Fast mode (without pretrained features)

    Example:
        $ cd scripts
        $ python predict_fast.py -type AIP -output_path ./ -test_fasta ../datasets/AIP/test.txt

3.1.2 Standard mode

    Example:
        $ cd scripts
        $ python predict.py -type AIP -output_path ./ -test_fasta ../datasets/AIP/test.txt -feature_file ../datasets/AIP/feature/test.h5
        
    Output:
    The result named after "{type}_prediction_result.csv" is saved in {output_path}. The four columns are represented peptide index, peptide sequence, the probability being AMP or AIM and the binary prediction category (1:positive, 0:negative), respectively.
    

3.2 Train a new deep model

3.2.1 Prepare the trianing and testing datasets.

	Kindly provide a FASTA file containing peptide names and sequences, with each peptide name followed by a label separated by a vertical bar "|".

	Example:
	>peptide0|1
	GLLDTFKNLALNAAKSAGVSVLNSLSCKLSKTC
	>peptide1|0
	METATLVAIFISCLLVSFTGYAPYTASGQPSNELRDLFEEHED

3.2.2 Training

	Example:
		$ cd script
		$ python train.py -type AIP -
	
	Output:
	Tha modified PDB files are saved in ../Datasets/customed_data/P{ligand}/modified_data/PDB

3.2.3 Generate the training, validation and test data sets from original data sets

    Example:
        $ cd scripts
        # demo 1
        $ python data_io.py --ligand DNA --psepos SC --features PSSM,HMM,SS,AF --context_radius 20
        # demo 2
        $ python data_io.py --ligand RNA --psepos SC --features PSSM,HMM,SS,AF --context_radius 20

    Output:
    The data sets are saved in ../Datasets/customed_data/P{ligand}/modified_data/P{ligand}_{psepos}_dist{context_radius}_{featurecode}.

    Note: {featurecode} is the combination of the first letter of {features}.
    Expected run time for the demo 1 and demo 2 on a "normal" desktop computer are 30 and 40 minutes, respectively.

    The list of commands:
    --ligand            A ligand type. It can be chosen from DNA,RNA,P.
    --psepos            Pseudo position of residues. SC, CA, C stand for centroid of side chain, alpha-C atom and centroid of residue, respectively.(default=SC)
    --features          Feature groups. Multiple features should be separated by commas. You can combine features from PSSM, HMM, SS(secondary structure) and AF(atom features).(default=PSSM,HMM,SS,AF)
    --context_radius    Radius of structure context.
    --tvseed            The random seed used to separate the validation set from training set.(default=1995)


3.2.4 Train the deep model

    Example:
        $ cd scripts
        # demo 1
        $ python training_gat.py --ligand DNA --psepos SC --features PSSM,HMM,SS,AF --context_radius 20 --edge_radius 10 --apply_edgeattr True --apply_posemb True --aggr sum --nlayers 4
        # demo 2
        $ python training_gat.py --ligand RNA --psepos SC --features PSSM,HMM,SS,AF --context_radius 20 --edge_radius 10 --apply_edgeattr True --apply_posemb True --nlayers 4

    Output:
    The trained model is saved in ../Datasets/P{ligand}/checkpoints/{starttime}.
    The log file of training details is saved in ../Datasets/P{ligand}/checkpoints/{starttime}/training.log.

    Note: {starttime} is the time when training.py started be executed.
    Expected run time for demo 1 and demo 2 on a "normal" desktop computer with a GPU are 30 and 12 hours, respectively.

    The list of commands:
    --ligand            A ligand type. It can be chosen from DNA,RNA,CA,MG,MN,ATP,HEME.
    --psepos            Pseudo position of residues. SC, CA, C stand for centroid of side chain, alpha-C atom and centroid of residue, respectively.(default=SC)
    --features          Feature groups. Multiple features should be separated by commas. You can combine features from PSSM, HMM, SS(secondary structure), AF(atom features) and OH (one-hot encoding features).(default=PSSM,HMM,SS,AF)
    --context_radius    Radius of structure context.
    --edge_radius       Radius of the neighborhood of a node. It should be smaller than radius of structure context.(default=20)
    --apply_edgeattr    Use the edge feature vectors or not.(default=True)
    --apply_posemb      Use the relative distance from every node to the central node as position embedding of nodes or not.(default=True)
    --aggr              The aggregation operation in node update module and graph update module. You can choose from sum and max.(default=sum)
    --hidden_size       The dimension of encoded edge, node and graph feature vector.(default=64)
    --nlayers         	The number of Geometric Graph Encoder (GGE).(default=4)
    --lr                Learning rate for training the deep model.(default=0.00005)
    --batch_size        Batch size for training deep model.(default=64)
    --epoch             Training epochs.(default=30)


4 Frequently Asked Questions
(1) If the script is interrupted by "Segmentation fault (core dumped)" when torch of CUDA version is used, it may be raised because the version of gcc (our version of gcc is 5.5.0) and you can try to set CUDA_VISIBLE_DEVICES to CPU before execute the script to avoid it by:
        $ export CUDA_VISIBLE_DEVICES="-1"
(2) If your CUDA version is not 10.0, please refer to the homepages of Pytorch(https://pytorch.org/) and torch_geometric (https://pytorch-geometric.readthedocs.io/en/latest/) to make sure that the installed dependencies match the CUDA version. Otherwise, the environment could be problematic due to the inconsistency.

5 How to cite PepNet?

   If you are using the PepNet program, you can cite:
   
```

